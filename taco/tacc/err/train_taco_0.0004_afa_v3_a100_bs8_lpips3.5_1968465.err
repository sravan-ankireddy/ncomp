10:54:08 INFO - logger_setup: /work/09004/sravana/ls6/ncomp/taco/utils/utils.py
10:54:08 INFO - ddp_or_single_process: Create new exp folder!
10:54:08 INFO - ddp_or_single_process: seed : 100.0
10:54:08 INFO - ddp_or_single_process: exp name : exp_lambda_0.0004_seed_100.0_batch_size_8_joint_image_text_loss_coefficient_0.0025_lpips_coefficient_3.5
10:54:08 INFO - ddp_or_single_process: opts: Namespace(aux_learning_rate=0.001, batch_size=8, checkpoint='None', clip_max_norm=1.0, dist_port=6412, epochs=50, joint_image_text_loss_coefficient=0.0025, learning_rate=0.0001, lmbda=0.0004, lpips_coefficient=3.5, lr_epoch=[45, 48], num_workers=12, patch_size=[256, 256], save_path='./checkpoint_afa_v3/exp_lambda_0.0004_seed_100.0_batch_size_8_joint_image_text_loss_coefficient_0.0025_lpips_coefficient_3.5', seed=100.0, train_dataset_root_path='/scratch/09004/sravana/MSCOCO', **{'ddp.world_size': 3, 'dev.num_gpus': 3})
10:54:16 INFO - logger_setup: /work/09004/sravana/ls6/ncomp/taco/utils/utils.py
10:54:16 INFO - logger_setup: /work/09004/sravana/ls6/ncomp/taco/utils/utils.py
10:54:16 INFO - logger_setup: /work/09004/sravana/ls6/ncomp/taco/utils/utils.py
10:54:16 INFO - main: Create experiment save folder
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
10:54:29 INFO - main: Training mode : scratch!
10:54:29 INFO - main: lambda : 0.0004
10:54:29 INFO - main: milestones: [45, 48]
10:54:29 INFO - main: batch_size : 8
10:54:29 INFO - main: Joint image-text loss coefficient: 0.0025
10:54:29 INFO - main: LPIPS coefficient: 3.5
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [192, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [192, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1712608851799/work/torch/csrc/distributed/c10d/reducer.cpp:325.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608851799/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
10:55:46 INFO - train_one_epoch: Train epoch 1: [0/137024 (0%)]	Loss: 20.939 |	MSE loss: 0.332 |	LPIPS loss: 0.981 |	Joint image-text loss: 117.937 |	Bpp loss: 8.58 |	Aux loss: 7918.32
11:00:28 INFO - train_one_epoch: Train epoch 1: [8000/137024 (6%)]	Loss: 1.553 |	MSE loss: 0.006 |	LPIPS loss: 0.194 |	Joint image-text loss: 69.912 |	Bpp loss: 0.55 |	Aux loss: 7333.17
11:05:11 INFO - train_one_epoch: Train epoch 1: [16000/137024 (12%)]	Loss: 1.223 |	MSE loss: 0.007 |	LPIPS loss: 0.114 |	Joint image-text loss: 58.270 |	Bpp loss: 0.49 |	Aux loss: 6440.18
11:09:54 INFO - train_one_epoch: Train epoch 1: [24000/137024 (18%)]	Loss: 1.187 |	MSE loss: 0.006 |	LPIPS loss: 0.112 |	Joint image-text loss: 53.935 |	Bpp loss: 0.50 |	Aux loss: 5201.76
11:14:38 INFO - train_one_epoch: Train epoch 1: [32000/137024 (23%)]	Loss: 1.041 |	MSE loss: 0.007 |	LPIPS loss: 0.090 |	Joint image-text loss: 47.371 |	Bpp loss: 0.43 |	Aux loss: 3552.05
11:19:23 INFO - train_one_epoch: Train epoch 1: [40000/137024 (29%)]	Loss: 1.019 |	MSE loss: 0.007 |	LPIPS loss: 0.081 |	Joint image-text loss: 48.151 |	Bpp loss: 0.43 |	Aux loss: 1292.45
11:24:06 INFO - train_one_epoch: Train epoch 1: [48000/137024 (35%)]	Loss: 0.740 |	MSE loss: 0.003 |	LPIPS loss: 0.054 |	Joint image-text loss: 41.355 |	Bpp loss: 0.37 |	Aux loss: 966.24
11:28:50 INFO - train_one_epoch: Train epoch 1: [56000/137024 (41%)]	Loss: 0.842 |	MSE loss: 0.005 |	LPIPS loss: 0.059 |	Joint image-text loss: 43.711 |	Bpp loss: 0.39 |	Aux loss: 2848.22
11:33:34 INFO - train_one_epoch: Train epoch 1: [64000/137024 (47%)]	Loss: 0.812 |	MSE loss: 0.005 |	LPIPS loss: 0.055 |	Joint image-text loss: 42.526 |	Bpp loss: 0.39 |	Aux loss: 4828.43
11:38:17 INFO - train_one_epoch: Train epoch 1: [72000/137024 (53%)]	Loss: 0.723 |	MSE loss: 0.003 |	LPIPS loss: 0.050 |	Joint image-text loss: 41.522 |	Bpp loss: 0.38 |	Aux loss: 6875.89
11:43:00 INFO - train_one_epoch: Train epoch 1: [80000/137024 (58%)]	Loss: 0.862 |	MSE loss: 0.005 |	LPIPS loss: 0.064 |	Joint image-text loss: 38.974 |	Bpp loss: 0.40 |	Aux loss: 9144.47
11:47:45 INFO - train_one_epoch: Train epoch 1: [88000/137024 (64%)]	Loss: 0.874 |	MSE loss: 0.007 |	LPIPS loss: 0.056 |	Joint image-text loss: 40.554 |	Bpp loss: 0.39 |	Aux loss: 11422.20
11:52:28 INFO - train_one_epoch: Train epoch 1: [96000/137024 (70%)]	Loss: 0.858 |	MSE loss: 0.006 |	LPIPS loss: 0.059 |	Joint image-text loss: 37.251 |	Bpp loss: 0.40 |	Aux loss: 13609.99
11:57:09 INFO - train_one_epoch: Train epoch 1: [104000/137024 (76%)]	Loss: 0.738 |	MSE loss: 0.004 |	LPIPS loss: 0.044 |	Joint image-text loss: 46.930 |	Bpp loss: 0.37 |	Aux loss: 15501.68
12:01:51 INFO - train_one_epoch: Train epoch 1: [112000/137024 (82%)]	Loss: 0.733 |	MSE loss: 0.004 |	LPIPS loss: 0.044 |	Joint image-text loss: 39.124 |	Bpp loss: 0.36 |	Aux loss: 17006.11
12:06:35 INFO - train_one_epoch: Train epoch 1: [120000/137024 (88%)]	Loss: 0.746 |	MSE loss: 0.004 |	LPIPS loss: 0.050 |	Joint image-text loss: 38.677 |	Bpp loss: 0.37 |	Aux loss: 17700.35
12:11:16 INFO - train_one_epoch: Train epoch 1: [128000/137024 (93%)]	Loss: 0.758 |	MSE loss: 0.005 |	LPIPS loss: 0.047 |	Joint image-text loss: 40.762 |	Bpp loss: 0.36 |	Aux loss: 17605.09
12:15:57 INFO - train_one_epoch: Train epoch 1: [136000/137024 (99%)]	Loss: 0.688 |	MSE loss: 0.003 |	LPIPS loss: 0.045 |	Joint image-text loss: 35.436 |	Bpp loss: 0.36 |	Aux loss: 16045.38
W0923 12:16:50.187763 22652608673600 torch/multiprocessing/spawn.py:145] Terminating process 747555 via signal SIGTERM
W0923 12:16:50.188822 22652608673600 torch/multiprocessing/spawn.py:145] Terminating process 747556 via signal SIGTERM
Traceback (most recent call last):
  File "train.py", line 523, in <module>
    ddp_or_single_process(sys.argv[1:])
  File "train.py", line 514, in ddp_or_single_process
    torch.multiprocessing.spawn(
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 281, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 237, in start_processes
    while not context.join():
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 75, in _wrap
    fn(i, *args)
  File "/work/09004/sravana/ls6/ncomp/taco/train.py", line 464, in distributed_worker
    main(opts)
  File "/work/09004/sravana/ls6/ncomp/taco/train.py", line 313, in main
    mean_PSNR, mean_MS_SSIM_prob, mean_LPIPS, Bit_rate = test_epoch(epoch, test_dataset, loss_fn_alex, net_eval, CLIP_text_model, train_dataset.tokenizer, f"{save_path}/figures/{epoch + 1}", logger)
  File "/work/09004/sravana/ls6/ncomp/taco/train.py", line 107, in test_epoch
    out_enc = model.compress(x_padded, text_embeddings)
  File "/work/09004/sravana/ls6/ncomp/taco/models/taco.py", line 168, in compress
    y = self.g_a(x, text_embeddings)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/09004/sravana/ls6/ncomp/taco/modules/transform/analysis.py", line 282, in forward
    x = layer(x, text_embeddings)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/09004/sravana/ls6/ncomp/taco/modules/transform/analysis.py", line 188, in forward
    attn_out_image_both, attn_weights_image_both = self.cross_attn_image_both(
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1266, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/functional.py", line 5470, in multi_head_attention_forward
    attn_output_weights = softmax(attn_output_weights, dim=-1)
  File "/work/09004/sravana/ls6/anaconda3/envs/taco/lib/python3.8/site-packages/torch/nn/functional.py", line 1885, in softmax
    ret = input.softmax(dim)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.03 GiB. GPU 

srun: error: c315-008: task 0: Exited with exit code 1
